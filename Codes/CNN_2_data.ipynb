{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e79590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:02.093631Z",
     "iopub.status.busy": "2025-03-26T11:52:02.093288Z",
     "iopub.status.idle": "2025-03-26T11:52:06.346750Z",
     "shell.execute_reply": "2025-03-26T11:52:06.346005Z"
    },
    "papermill": {
     "duration": 4.260302,
     "end_time": "2025-03-26T11:52:06.348286",
     "exception": false,
     "start_time": "2025-03-26T11:52:02.087984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, pathlib, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132577cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:06.356583Z",
     "iopub.status.busy": "2025-03-26T11:52:06.356221Z",
     "iopub.status.idle": "2025-03-26T11:52:06.428571Z",
     "shell.execute_reply": "2025-03-26T11:52:06.427636Z"
    },
    "papermill": {
     "duration": 0.077951,
     "end_time": "2025-03-26T11:52:06.430189",
     "exception": false,
     "start_time": "2025-03-26T11:52:06.352238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0296a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:06.438815Z",
     "iopub.status.busy": "2025-03-26T11:52:06.438542Z",
     "iopub.status.idle": "2025-03-26T11:52:06.441718Z",
     "shell.execute_reply": "2025-03-26T11:52:06.441061Z"
    },
    "papermill": {
     "duration": 0.008603,
     "end_time": "2025-03-26T11:52:06.442987",
     "exception": false,
     "start_time": "2025-03-26T11:52:06.434384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa85968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:06.450773Z",
     "iopub.status.busy": "2025-03-26T11:52:06.450533Z",
     "iopub.status.idle": "2025-03-26T11:52:14.012038Z",
     "shell.execute_reply": "2025-03-26T11:52:14.010999Z"
    },
    "papermill": {
     "duration": 7.566738,
     "end_time": "2025-03-26T11:52:14.013281",
     "exception": false,
     "start_time": "2025-03-26T11:52:06.446543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 195996\n",
      "Validation samples: 42004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Paths for both datasets\n",
    "train_data_paths = [\n",
    "    r\"/kaggle/input/jpd-df2-lfcc/LFCC_T1/train\",  # Language 1\n",
    "    r\"/kaggle/input/jpd-df2-lfcc-t2/LFCC/train\"   # Language 2\n",
    "]\n",
    "validation_data_paths = [\n",
    "    r\"/kaggle/input/jpd-df2-lfcc/LFCC_T1/val\",\n",
    "    r\"/kaggle/input/jpd-df2-lfcc-t2/LFCC/val\"\n",
    "]\n",
    "\n",
    "class MixedPtDataset(Dataset):\n",
    "    def __init__(self, directories):\n",
    "        \"\"\"Load features from multiple directories.\"\"\"\n",
    "        self.files = []\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "        for directory in directories:\n",
    "            classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "            \n",
    "            # Assign class indices if not already assigned\n",
    "            for c in classes:\n",
    "                if c not in self.class_to_idx:\n",
    "                    self.class_to_idx[c] = len(self.class_to_idx)\n",
    "\n",
    "            for c in classes:\n",
    "                c_dir = os.path.join(directory, c)\n",
    "                c_files = [(os.path.join(c_dir, f), self.class_to_idx[c]) for f in os.listdir(c_dir)]\n",
    "                self.files.extend(c_files)\n",
    "\n",
    "        random.shuffle(self.files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath, label = self.files[idx]\n",
    "        try:\n",
    "            mat_vals = scipy.io.loadmat(filepath)\n",
    "            data = mat_vals['final'].T\n",
    "            max_len = 800\n",
    "            if max_len > data.shape[0]:\n",
    "                pad_width = max_len - data.shape[0]\n",
    "                data = np.pad(data, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                data = data[:max_len, :]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {filepath}: {str(e)}\")\n",
    "            return None\n",
    "        return data, label\n",
    "\n",
    "# Combine both datasets\n",
    "train_dataset = MixedPtDataset(train_data_paths)\n",
    "val_dataset = MixedPtDataset(validation_data_paths)\n",
    "\n",
    "class PtDataLoader(DataLoader):\n",
    "    def __init__(self, directories, batch_size, shuffle=True):\n",
    "        dataset = MixedPtDataset(directories)\n",
    "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Load mixed datasets\n",
    "batch_size = 32\n",
    "train_dataloader = PtDataLoader(directories=train_data_paths, batch_size=batch_size)\n",
    "val_dataloader = PtDataLoader(directories=validation_data_paths, batch_size=batch_size)\n",
    "\n",
    "train_count = len(train_dataset)\n",
    "val_count = len(val_dataset)\n",
    "\n",
    "print(f\"Training samples: {train_count}\\nValidation samples: {val_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9578248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.021746Z",
     "iopub.status.busy": "2025-03-26T11:52:14.021391Z",
     "iopub.status.idle": "2025-03-26T11:52:14.025659Z",
     "shell.execute_reply": "2025-03-26T11:52:14.024870Z"
    },
    "papermill": {
     "duration": 0.00986,
     "end_time": "2025-03-26T11:52:14.027040",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.017180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195996\n",
      "42004\n"
     ]
    }
   ],
   "source": [
    "print(train_count)\n",
    "# print(test_count)\n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67768a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.035066Z",
     "iopub.status.busy": "2025-03-26T11:52:14.034861Z",
     "iopub.status.idle": "2025-03-26T11:52:14.037847Z",
     "shell.execute_reply": "2025-03-26T11:52:14.037230Z"
    },
    "papermill": {
     "duration": 0.008314,
     "end_time": "2025-03-26T11:52:14.039096",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.030782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073c0d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.046905Z",
     "iopub.status.busy": "2025-03-26T11:52:14.046693Z",
     "iopub.status.idle": "2025-03-26T11:52:14.049849Z",
     "shell.execute_reply": "2025-03-26T11:52:14.049185Z"
    },
    "papermill": {
     "duration": 0.008322,
     "end_time": "2025-03-26T11:52:14.051008",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.042686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "input_size = 20\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "# drop_amount = 0.25  # You can choose an appropriate dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0c8e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.058945Z",
     "iopub.status.busy": "2025-03-26T11:52:14.058744Z",
     "iopub.status.idle": "2025-03-26T11:52:14.061775Z",
     "shell.execute_reply": "2025-03-26T11:52:14.061097Z"
    },
    "papermill": {
     "duration": 0.008193,
     "end_time": "2025-03-26T11:52:14.062943",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.054750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c900531d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.070836Z",
     "iopub.status.busy": "2025-03-26T11:52:14.070609Z",
     "iopub.status.idle": "2025-03-26T11:52:33.226166Z",
     "shell.execute_reply": "2025-03-26T11:52:33.225260Z"
    },
    "papermill": {
     "duration": 19.161577,
     "end_time": "2025-03-26T11:52:33.228190",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.066613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, pathlib, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from transformers.models.whisper.modeling_whisper import WhisperModel, WhisperEncoder\n",
    "from transformers.models.whisper.configuration_whisper import WhisperConfig\n",
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "import librosa \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob, pickle\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8363f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.243551Z",
     "iopub.status.busy": "2025-03-26T11:52:33.242968Z",
     "iopub.status.idle": "2025-03-26T11:52:33.246625Z",
     "shell.execute_reply": "2025-03-26T11:52:33.245827Z"
    },
    "papermill": {
     "duration": 0.012366,
     "end_time": "2025-03-26T11:52:33.247894",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.235528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb0c6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.256171Z",
     "iopub.status.busy": "2025-03-26T11:52:33.255874Z",
     "iopub.status.idle": "2025-03-26T11:52:33.264529Z",
     "shell.execute_reply": "2025-03-26T11:52:33.263779Z"
    },
    "papermill": {
     "duration": 0.014185,
     "end_time": "2025-03-26T11:52:33.265748",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.251563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        # Extract the output of the last time step from both directions\n",
    "        last_hidden_state = torch.cat((out[:, -1, :self.hidden_size], out[:, 0, self.hidden_size:]), dim=1)\n",
    "        output = self.fc(last_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52db27b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.273806Z",
     "iopub.status.busy": "2025-03-26T11:52:33.273485Z",
     "iopub.status.idle": "2025-03-26T11:52:33.642685Z",
     "shell.execute_reply": "2025-03-26T11:52:33.641730Z"
    },
    "papermill": {
     "duration": 0.374895,
     "end_time": "2025-03-26T11:52:33.644194",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.269299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (lstm): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003\n",
    "model = BiLSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "735296cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.653002Z",
     "iopub.status.busy": "2025-03-26T11:52:33.652736Z",
     "iopub.status.idle": "2025-03-26T11:52:33.686826Z",
     "shell.execute_reply": "2025-03-26T11:52:33.685710Z"
    },
    "papermill": {
     "duration": 0.039942,
     "end_time": "2025-03-26T11:52:33.688254",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.648312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (lstm): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183e5099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.698363Z",
     "iopub.status.busy": "2025-03-26T11:52:33.698048Z",
     "iopub.status.idle": "2025-03-26T11:52:33.713805Z",
     "shell.execute_reply": "2025-03-26T11:52:33.712936Z"
    },
    "papermill": {
     "duration": 0.02188,
     "end_time": "2025-03-26T11:52:33.715197",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.693317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming input x shape is (batch_size, sequence_length, input_channels)\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, input_channels, sequence_length)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.adaptive_max_pool1d(x, 1)  # Pool to a fixed size (1)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003\n",
    "\n",
    "input_channels = 20  # You can change this depending on your input data\n",
    "num_classes = 2  # Adjust according to your classification task\n",
    "\n",
    "model = CNNClassifier(input_channels, num_classes)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61264619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.725663Z",
     "iopub.status.busy": "2025-03-26T11:52:33.725347Z",
     "iopub.status.idle": "2025-03-26T11:52:33.729704Z",
     "shell.execute_reply": "2025-03-26T11:52:33.728856Z"
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2025-03-26T11:52:33.731008",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.719907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf61e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.739573Z",
     "iopub.status.busy": "2025-03-26T11:52:33.739319Z",
     "iopub.status.idle": "2025-03-26T14:11:47.318550Z",
     "shell.execute_reply": "2025-03-26T14:11:47.317539Z"
    },
    "papermill": {
     "duration": 8353.585029,
     "end_time": "2025-03-26T14:11:47.319927",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.734898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [30:14<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [07:54<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10   Train Loss: 0.3004   Train Accuracy: 0.8733   Validation Accuracy: 0.9183\n",
      "\n",
      "Epoch 2/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [10:32<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [01:49<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10   Train Loss: 0.1924   Train Accuracy: 0.9263   Validation Accuracy: 0.9460\n",
      "\n",
      "Epoch 3/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [08:58<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [01:35<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10   Train Loss: 0.1734   Train Accuracy: 0.9333   Validation Accuracy: 0.9482\n",
      "\n",
      "Epoch 4/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [09:16<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [02:03<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10   Train Loss: 0.1613   Train Accuracy: 0.9384   Validation Accuracy: 0.9513\n",
      "\n",
      "Epoch 5/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [09:12<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [02:03<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10   Train Loss: 0.1557   Train Accuracy: 0.9410   Validation Accuracy: 0.9544\n",
      "\n",
      "Epoch 6/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [09:54<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [02:11<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10   Train Loss: 0.1517   Train Accuracy: 0.9424   Validation Accuracy: 0.9422\n",
      "\n",
      "Epoch 7/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [09:54<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [02:04<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10   Train Loss: 0.1514   Train Accuracy: 0.9422   Validation Accuracy: 0.9499\n",
      "\n",
      "Epoch 8/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [09:18<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [01:28<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10   Train Loss: 0.1518   Train Accuracy: 0.9435   Validation Accuracy: 0.9355\n",
      "\n",
      "Epoch 9/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [08:58<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [01:40<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10   Train Loss: 0.1477   Train Accuracy: 0.9441   Validation Accuracy: 0.9363\n",
      "\n",
      "Epoch 10/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 6125/6125 [08:19<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|██████████| 1313/1313 [01:42<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10   Train Loss: 0.1462   Train Accuracy: 0.9455   Validation Accuracy: 0.9510\n",
      "\n",
      "Maximum Validation Accuracy: 0.9544\n",
      "Finished Training and Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Model training and testing\n",
    "n_total_steps = len(train_dataloader)\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "val_accuracy_list = []\n",
    "max_acc = 0\n",
    "num_epochs = 10\n",
    "pred_labels = []\n",
    "act_labels = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Training...\")\n",
    "\n",
    "    # Use tqdm for training loop\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(train_dataloader, desc=\"Training Batches\")):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "    train_accuracy /= train_count\n",
    "    train_loss /= train_count\n",
    "    \n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    pred = []\n",
    "    lab = []\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Validation...\")\n",
    "\n",
    "    # Use tqdm for validation loop\n",
    "    for i, (images, labels) in enumerate(tqdm(val_dataloader, desc=\"Validation Batches\")):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        val_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "        pred.extend(prediction.tolist())\n",
    "        lab.extend(labels.tolist())\n",
    "\n",
    "    val_accuracy /= val_count\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "    # Save the best model\n",
    "    if max_acc < val_accuracy:\n",
    "        max_acc = val_accuracy\n",
    "        pred_labels = pred\n",
    "        act_labels = lab\n",
    "        torch.save(model, \"best_accuracy_model_BiLSTM.pth\")\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}   \"\n",
    "          f\"Train Loss: {train_loss:.4f}   \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}   \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nMaximum Validation Accuracy: {max_acc:.4f}\")\n",
    "print('Finished Training and Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf254235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:11:51.523963Z",
     "iopub.status.busy": "2025-03-26T14:11:51.523672Z",
     "iopub.status.idle": "2025-03-26T14:11:51.526968Z",
     "shell.execute_reply": "2025-03-26T14:11:51.526311Z"
    },
    "papermill": {
     "duration": 2.051802,
     "end_time": "2025-03-26T14:11:51.528238",
     "exception": false,
     "start_time": "2025-03-26T14:11:49.476436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# best_model = torch.load(\"best_accuracy_model_BiLSTM.pth\")\n",
    "\n",
    "# # Put the best_model in evaluation mode\n",
    "# best_model.eval()\n",
    "\n",
    "# # Initialize variables to store results\n",
    "# testing_accuracy = 0.0\n",
    "# pred_labels = []\n",
    "# act_labels = []\n",
    "\n",
    "# # Pass validation data through the best model\n",
    "# for i, (images, labels) in enumerate(test_dataloader):\n",
    "#     if torch.cuda.is_available():\n",
    "#         images = Variable(images.cuda())\n",
    "#         labels = Variable(labels.cuda())\n",
    "    \n",
    "#     outputs = best_model(images)\n",
    "#     _, prediction = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     testing_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "#     pred_labels.extend(prediction.tolist())\n",
    "#     act_labels.extend(labels.tolist())\n",
    "\n",
    "# # Calculate validation accuracy\n",
    "# testing_accuracy = testing_accuracy / len(test_dataloader.dataset)\n",
    "\n",
    "# # Print the validation accuracy\n",
    "# print(\"testing Accuracy:\", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "304afb80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:11:55.613778Z",
     "iopub.status.busy": "2025-03-26T14:11:55.613480Z",
     "iopub.status.idle": "2025-03-26T14:11:55.616746Z",
     "shell.execute_reply": "2025-03-26T14:11:55.616021Z"
    },
    "papermill": {
     "duration": 2.04445,
     "end_time": "2025-03-26T14:11:55.617926",
     "exception": false,
     "start_time": "2025-03-26T14:11:53.573476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Calculate the confusion matrix\n",
    "# import seaborn as sns\n",
    "# conf_mat = confusion_matrix(act_labels, pred_labels)\n",
    "# # Plot confusion matrix heat map\n",
    "# sns.heatmap(conf_mat, cmap=\"flare\",annot=True, fmt = \"g\", \n",
    "#             cbar_kws={\"label\":\"color bar\"},\n",
    "#             xticklabels=train_dataset.classes,\n",
    "#             yticklabels=train_dataset.classes)\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Actual\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.savefig(\"ConfusionMatrix_BiLSTM.png\")\n",
    "# plt.show()\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1_score = f1_score(pred_labels, act_labels, average='macro')\n",
    "# print('F1 Score : ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "156cac38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:11:59.731597Z",
     "iopub.status.busy": "2025-03-26T14:11:59.731103Z",
     "iopub.status.idle": "2025-03-26T14:11:59.735557Z",
     "shell.execute_reply": "2025-03-26T14:11:59.734846Z"
    },
    "papermill": {
     "duration": 2.04668,
     "end_time": "2025-03-26T14:11:59.736809",
     "exception": false,
     "start_time": "2025-03-26T14:11:57.690129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import sklearn.metrics\n",
    "\n",
    "# \"\"\"\n",
    "# Python compute equal error rate (eer)\n",
    "# ONLY tested on binary classification\n",
    "\n",
    "# :param label: ground-truth label, should be a 1-d list or np.array, each element represents the ground-truth label of one sample\n",
    "# :param pred: model prediction, should be a 1-d list or np.array, each element represents the model prediction of one sample\n",
    "# :param positive_label: the class that is viewed as positive class when computing EER\n",
    "# :return: equal error rate (EER)\n",
    "# \"\"\"\n",
    "# def compute_eer(label, pred):\n",
    "#     # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "#     fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred)\n",
    "#     fnr = 1 - tpr\n",
    "\n",
    "#     # the threshold of fnr == fpr\n",
    "#     eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "#     # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "#     eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "#     eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "#     # return the mean of eer from fpr and from fnr\n",
    "#     eer = (eer_1 + eer_2) / 2\n",
    "#     return eer\n",
    "\n",
    "# eer = compute_eer(act_labels, pred_labels)\n",
    "# print('The equal error rate is {:.3f}'.format(eer))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6960546,
     "sourceId": 11156044,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6961676,
     "sourceId": 11157532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8405.900968,
   "end_time": "2025-03-26T14:12:05.296858",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T11:51:59.395890",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
