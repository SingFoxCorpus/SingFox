{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12105654,"sourceType":"datasetVersion","datasetId":7621389},{"sourceId":12613456,"sourceType":"datasetVersion","datasetId":7968028}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://huggingface.co/Higobeatz/Diff-Pitcher\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:04:17.214292Z","iopub.execute_input":"2025-07-29T18:04:17.214483Z","iopub.status.idle":"2025-07-29T18:04:38.888330Z","shell.execute_reply.started":"2025-07-29T18:04:17.214455Z","shell.execute_reply":"2025-07-29T18:04:38.887424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd Diff-Pitcher","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:04:38.891797Z","iopub.execute_input":"2025-07-29T18:04:38.892016Z","iopub.status.idle":"2025-07-29T18:04:38.897604Z","shell.execute_reply.started":"2025-07-29T18:04:38.891996Z","shell.execute_reply":"2025-07-29T18:04:38.896878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:06:39.523514Z","iopub.execute_input":"2025-07-29T18:06:39.524024Z","iopub.status.idle":"2025-07-29T18:09:10.974671Z","shell.execute_reply.started":"2025-07-29T18:06:39.523998Z","shell.execute_reply":"2025-07-29T18:09:10.973747Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/Diff-Pitcher/template_based_apc.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:09:10.976453Z","iopub.execute_input":"2025-07-29T18:09:10.976698Z","iopub.status.idle":"2025-07-29T18:09:41.037594Z","shell.execute_reply.started":"2025-07-29T18:09:10.976676Z","shell.execute_reply":"2025-07-29T18:09:41.036671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pydub import AudioSegment\nimport os\n\ninput_dir = \"/kaggle/input/dir4-singfox/Directory 4/songs/English\"  # or path to folder with .mp3 files\noutput_dir = \"/kaggle/working/resampled_wavs\"\nos.makedirs(output_dir, exist_ok=True)\n\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith(\".wav\"):\n        mp3_path = os.path.join(input_dir, file_name)\n        wav_name = os.path.splitext(file_name)[0] + \".wav\"\n        wav_path = os.path.join(output_dir, wav_name)\n\n        # Load and resample\n        audio = AudioSegment.from_mp3(mp3_path)\n        audio = audio.set_frame_rate(24000)\n        audio.export(wav_path, format=\"wav\")\n        print(f\"Converted: {file_name} â†’ {wav_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:44:02.642185Z","iopub.execute_input":"2025-07-29T18:44:02.642916Z","iopub.status.idle":"2025-07-29T18:44:02.687148Z","shell.execute_reply.started":"2025-07-29T18:44:02.642886Z","shell.execute_reply":"2025-07-29T18:44:02.686566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile ChebyshevKANLinear.py\n\nimport os.path\nimport numpy as np\nimport pandas as pd\nimport torch\nimport yaml\nimport librosa\nimport soundfile as sf\nfrom tqdm import tqdm\n\nfrom diffusers import DDIMScheduler\nfrom pitch_controller.models.unet import UNetPitcher\nfrom pitch_controller.utils import minmax_norm_diff, reverse_minmax_norm_diff\nfrom pitch_controller.modules.BigVGAN.inference import load_model\nfrom utils import get_mel, get_world_mel, get_f0, f0_to_coarse, show_plot, get_matched_f0, log_f0\n\n\n@torch.no_grad()\ndef template_pitcher(source, pitch_ref, model, hifigan, steps=50, shift_semi=0):\n\n    source_mel = get_world_mel(source, sr=sr)\n\n    f0_ref = get_matched_f0(source, pitch_ref, 'world')\n    f0_ref = f0_ref * 2 ** (shift_semi / 12)\n\n    f0_ref = log_f0(f0_ref, {'f0_bin': 345,\n                             'f0_min': librosa.note_to_hz('C2'),\n                             'f0_max': librosa.note_to_hz('C#6')})\n\n    source_mel = torch.from_numpy(source_mel).float().unsqueeze(0).to(device)\n    f0_ref = torch.from_numpy(f0_ref).float().unsqueeze(0).to(device)\n\n    noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n    generator = torch.Generator(device=device).manual_seed(2024)\n\n    noise_scheduler.set_timesteps(steps)\n    noise = torch.randn(source_mel.shape, generator=generator, device=device)\n    pred = noise\n    source_x = minmax_norm_diff(source_mel, vmax=max_mel, vmin=min_mel)\n\n    for t in tqdm(noise_scheduler.timesteps):\n        pred = noise_scheduler.scale_model_input(pred, t)\n        model_output = model(x=pred, mean=source_x, f0=f0_ref, t=t, ref=None, embed=None)\n        pred = noise_scheduler.step(model_output=model_output,\n                                    timestep=t,\n                                    sample=pred,\n                                    eta=1, generator=generator).prev_sample\n\n    pred = reverse_minmax_norm_diff(pred, vmax=max_mel, vmin=min_mel)\n\n    pred_audio = hifigan(pred)\n    pred_audio = pred_audio.cpu().squeeze().clamp(-1, 1)\n\n    return pred_audio\n\n\nif __name__ == '__main__':\n    min_mel = np.log(1e-5)\n    max_mel = 2.5\n    sr = 24000\n\n    use_gpu = torch.cuda.is_available()\n    device = 'cuda' if use_gpu else 'cpu'\n\n    # load diffusion model\n    config = yaml.load(open('pitch_controller/config/DiffWorld_24k.yaml'), Loader=yaml.FullLoader)\n    mel_cfg = config['logmel']\n    ddpm_cfg = config['ddpm']\n    unet_cfg = config['unet']\n    model = UNetPitcher(**unet_cfg)\n    unet_path = 'ckpts/world_fixed_40.pt'\n\n    state_dict = torch.load(unet_path)\n    for key in list(state_dict.keys()):\n        state_dict[key.replace('_orig_mod.', '')] = state_dict.pop(key)\n    model.load_state_dict(state_dict)\n    if use_gpu:\n        model.cuda()\n    model.eval()\n\n    #  load vocoder\n    hifi_path = 'ckpts/bigvgan_24khz_100band/g_05000000.pt'\n    hifigan, cfg = load_model(hifi_path, device=device)\n    hifigan.eval()\n\n    # pred_audio = template_pitcher('/kaggle/working/resampled_wavs/en_20.wav', '/kaggle/working/resampled_wavs/en_19.wav', model, hifigan, steps=50, shift_semi=0)\n    import random\n\n    resampled_folder = \"/kaggle/working/resampled_wavs\"\n    output_folder = \"/kaggle/working/English_saved_wavs\"\n    os.makedirs(output_folder, exist_ok=True)\n    \n    resampled_files = [f for f in os.listdir(resampled_folder) if f.endswith(\".wav\")]\n    \n    for i, src_file in enumerate(resampled_files):\n        pitch_ref_file = random.choice(resampled_files)\n        while pitch_ref_file == src_file:\n            pitch_ref_file = random.choice(resampled_files)\n    \n        src_path = os.path.join(resampled_folder, src_file)\n        ref_path = os.path.join(resampled_folder, pitch_ref_file)\n    \n        print(f\"\\n>> Generating for: {src_file} using pitch of {pitch_ref_file}\")\n        try:\n            pred_audio = template_pitcher(src_path, ref_path, model, hifigan, steps=50, shift_semi=0)\n            save_path = os.path.join(output_folder, f\"deepfake_{os.path.splitext(src_file)[0]}_from_{os.path.splitext(pitch_ref_file)[0]}.wav\")\n            sf.write(save_path, pred_audio, samplerate=sr)\n        except Exception as e:\n            print(f\"[ERROR] {src_file} skipped due to: {e}\")\n\n    # sf.write('/kaggle/working/Diff-Pitcher/imgs/output_template_new.wav', pred_audio, samplerate=sr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:56:54.907738Z","iopub.execute_input":"2025-07-29T18:56:54.908627Z","iopub.status.idle":"2025-07-29T18:56:54.915751Z","shell.execute_reply.started":"2025-07-29T18:56:54.908596Z","shell.execute_reply":"2025-07-29T18:56:54.915115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/Diff-Pitcher/ChebyshevKANLinear.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T18:56:56.322750Z","iopub.execute_input":"2025-07-29T18:56:56.323037Z","iopub.status.idle":"2025-07-29T19:00:08.346146Z","shell.execute_reply.started":"2025-07-29T18:56:56.323015Z","shell.execute_reply":"2025-07-29T19:00:08.345201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/English_saved_wavs\nfrom IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}