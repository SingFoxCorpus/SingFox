{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30577d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:03.307573Z",
     "iopub.status.busy": "2025-03-26T11:52:03.307247Z",
     "iopub.status.idle": "2025-03-26T11:52:07.496037Z",
     "shell.execute_reply": "2025-03-26T11:52:07.495316Z"
    },
    "papermill": {
     "duration": 4.196204,
     "end_time": "2025-03-26T11:52:07.497589",
     "exception": false,
     "start_time": "2025-03-26T11:52:03.301385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, pathlib, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce11579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:07.507312Z",
     "iopub.status.busy": "2025-03-26T11:52:07.506904Z",
     "iopub.status.idle": "2025-03-26T11:52:07.577253Z",
     "shell.execute_reply": "2025-03-26T11:52:07.576211Z"
    },
    "papermill": {
     "duration": 0.076322,
     "end_time": "2025-03-26T11:52:07.578552",
     "exception": false,
     "start_time": "2025-03-26T11:52:07.502230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2c90c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:07.589020Z",
     "iopub.status.busy": "2025-03-26T11:52:07.588730Z",
     "iopub.status.idle": "2025-03-26T11:52:07.592381Z",
     "shell.execute_reply": "2025-03-26T11:52:07.591485Z"
    },
    "papermill": {
     "duration": 0.009967,
     "end_time": "2025-03-26T11:52:07.593762",
     "exception": false,
     "start_time": "2025-03-26T11:52:07.583795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6edbfd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:07.602880Z",
     "iopub.status.busy": "2025-03-26T11:52:07.602628Z",
     "iopub.status.idle": "2025-03-26T11:52:14.033559Z",
     "shell.execute_reply": "2025-03-26T11:52:14.032640Z"
    },
    "papermill": {
     "duration": 6.437241,
     "end_time": "2025-03-26T11:52:14.035291",
     "exception": false,
     "start_time": "2025-03-26T11:52:07.598050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 195996\n",
      "Validation samples: 42004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Paths for both datasets\n",
    "train_data_paths = [\n",
    "    r\"/kaggle/input/jpd-df2-lfcc/LFCC_T1/train\",  # Language 1\n",
    "    r\"/kaggle/input/jpd-df2-lfcc-t2/LFCC/train\"   # Language 2\n",
    "]\n",
    "validation_data_paths = [\n",
    "    r\"/kaggle/input/jpd-df2-lfcc/LFCC_T1/val\",\n",
    "    r\"/kaggle/input/jpd-df2-lfcc-t2/LFCC/val\"\n",
    "]\n",
    "\n",
    "class MixedPtDataset(Dataset):\n",
    "    def __init__(self, directories):\n",
    "        \"\"\"Load features from multiple directories.\"\"\"\n",
    "        self.files = []\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "        for directory in directories:\n",
    "            classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "            \n",
    "            # Assign class indices if not already assigned\n",
    "            for c in classes:\n",
    "                if c not in self.class_to_idx:\n",
    "                    self.class_to_idx[c] = len(self.class_to_idx)\n",
    "\n",
    "            for c in classes:\n",
    "                c_dir = os.path.join(directory, c)\n",
    "                c_files = [(os.path.join(c_dir, f), self.class_to_idx[c]) for f in os.listdir(c_dir)]\n",
    "                self.files.extend(c_files)\n",
    "\n",
    "        random.shuffle(self.files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath, label = self.files[idx]\n",
    "        try:\n",
    "            mat_vals = scipy.io.loadmat(filepath)\n",
    "            data = mat_vals['final'].T\n",
    "            max_len = 800\n",
    "            if max_len > data.shape[0]:\n",
    "                pad_width = max_len - data.shape[0]\n",
    "                data = np.pad(data, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                data = data[:max_len, :]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {filepath}: {str(e)}\")\n",
    "            return None\n",
    "        return data, label\n",
    "\n",
    "# Combine both datasets\n",
    "train_dataset = MixedPtDataset(train_data_paths)\n",
    "val_dataset = MixedPtDataset(validation_data_paths)\n",
    "\n",
    "class PtDataLoader(DataLoader):\n",
    "    def __init__(self, directories, batch_size, shuffle=True):\n",
    "        dataset = MixedPtDataset(directories)\n",
    "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Load mixed datasets\n",
    "batch_size = 32\n",
    "train_dataloader = PtDataLoader(directories=train_data_paths, batch_size=batch_size)\n",
    "val_dataloader = PtDataLoader(directories=validation_data_paths, batch_size=batch_size)\n",
    "\n",
    "train_count = len(train_dataset)\n",
    "val_count = len(val_dataset)\n",
    "\n",
    "print(f\"Training samples: {train_count}\\nValidation samples: {val_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2b9cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.046503Z",
     "iopub.status.busy": "2025-03-26T11:52:14.046175Z",
     "iopub.status.idle": "2025-03-26T11:52:14.050793Z",
     "shell.execute_reply": "2025-03-26T11:52:14.049948Z"
    },
    "papermill": {
     "duration": 0.011445,
     "end_time": "2025-03-26T11:52:14.052084",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.040639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195996\n",
      "42004\n"
     ]
    }
   ],
   "source": [
    "print(train_count)\n",
    "# print(test_count)\n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0faca5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.061462Z",
     "iopub.status.busy": "2025-03-26T11:52:14.061204Z",
     "iopub.status.idle": "2025-03-26T11:52:14.064755Z",
     "shell.execute_reply": "2025-03-26T11:52:14.063951Z"
    },
    "papermill": {
     "duration": 0.009933,
     "end_time": "2025-03-26T11:52:14.066254",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.056321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ad6c1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.075584Z",
     "iopub.status.busy": "2025-03-26T11:52:14.075312Z",
     "iopub.status.idle": "2025-03-26T11:52:14.078609Z",
     "shell.execute_reply": "2025-03-26T11:52:14.078006Z"
    },
    "papermill": {
     "duration": 0.009442,
     "end_time": "2025-03-26T11:52:14.080030",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.070588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "input_size = 20\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "# drop_amount = 0.25  # You can choose an appropriate dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ee04c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.089185Z",
     "iopub.status.busy": "2025-03-26T11:52:14.088887Z",
     "iopub.status.idle": "2025-03-26T11:52:14.092300Z",
     "shell.execute_reply": "2025-03-26T11:52:14.091487Z"
    },
    "papermill": {
     "duration": 0.009349,
     "end_time": "2025-03-26T11:52:14.093664",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.084315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e6b741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:14.103042Z",
     "iopub.status.busy": "2025-03-26T11:52:14.102763Z",
     "iopub.status.idle": "2025-03-26T11:52:33.258980Z",
     "shell.execute_reply": "2025-03-26T11:52:33.258057Z"
    },
    "papermill": {
     "duration": 19.162807,
     "end_time": "2025-03-26T11:52:33.260725",
     "exception": false,
     "start_time": "2025-03-26T11:52:14.097918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, pathlib, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from transformers.models.whisper.modeling_whisper import WhisperModel, WhisperEncoder\n",
    "from transformers.models.whisper.configuration_whisper import WhisperConfig\n",
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "import librosa \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob, pickle\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba2c7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.270857Z",
     "iopub.status.busy": "2025-03-26T11:52:33.270348Z",
     "iopub.status.idle": "2025-03-26T11:52:33.273554Z",
     "shell.execute_reply": "2025-03-26T11:52:33.272896Z"
    },
    "papermill": {
     "duration": 0.00938,
     "end_time": "2025-03-26T11:52:33.274791",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.265411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2b4a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.284322Z",
     "iopub.status.busy": "2025-03-26T11:52:33.284058Z",
     "iopub.status.idle": "2025-03-26T11:52:33.290496Z",
     "shell.execute_reply": "2025-03-26T11:52:33.289810Z"
    },
    "papermill": {
     "duration": 0.012489,
     "end_time": "2025-03-26T11:52:33.291738",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.279249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        # Extract the output of the last time step from both directions\n",
    "        last_hidden_state = torch.cat((out[:, -1, :self.hidden_size], out[:, 0, self.hidden_size:]), dim=1)\n",
    "        output = self.fc(last_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6131c913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.300959Z",
     "iopub.status.busy": "2025-03-26T11:52:33.300678Z",
     "iopub.status.idle": "2025-03-26T11:52:33.304035Z",
     "shell.execute_reply": "2025-03-26T11:52:33.303256Z"
    },
    "papermill": {
     "duration": 0.009348,
     "end_time": "2025-03-26T11:52:33.305422",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.296074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b0a97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.314678Z",
     "iopub.status.busy": "2025-03-26T11:52:33.314434Z",
     "iopub.status.idle": "2025-03-26T11:52:33.669548Z",
     "shell.execute_reply": "2025-03-26T11:52:33.668439Z"
    },
    "papermill": {
     "duration": 0.361167,
     "end_time": "2025-03-26T11:52:33.670911",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.309744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (lstm): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f03d4e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.680684Z",
     "iopub.status.busy": "2025-03-26T11:52:33.680426Z",
     "iopub.status.idle": "2025-03-26T11:52:33.686712Z",
     "shell.execute_reply": "2025-03-26T11:52:33.686013Z"
    },
    "papermill": {
     "duration": 0.012512,
     "end_time": "2025-03-26T11:52:33.687915",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.675403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming input x shape is (batch_size, sequence_length, input_channels)\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, input_channels, sequence_length)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.adaptive_max_pool1d(x, 1)  # Pool to a fixed size (1)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6528a36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.697622Z",
     "iopub.status.busy": "2025-03-26T11:52:33.697358Z",
     "iopub.status.idle": "2025-03-26T11:52:33.700776Z",
     "shell.execute_reply": "2025-03-26T11:52:33.700106Z"
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2025-03-26T11:52:33.702106",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.692411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 2\n",
    "learning_rate = 0.003\n",
    "\n",
    "input_channels = 20  # You can change this depending on your input data\n",
    "num_classes = 2  # Adjust according to your classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df11ec47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.711371Z",
     "iopub.status.busy": "2025-03-26T11:52:33.711103Z",
     "iopub.status.idle": "2025-03-26T11:52:33.719560Z",
     "shell.execute_reply": "2025-03-26T11:52:33.718677Z"
    },
    "papermill": {
     "duration": 0.014524,
     "end_time": "2025-03-26T11:52:33.720834",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.706310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNNClassifier(input_channels, num_classes)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e92309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.730592Z",
     "iopub.status.busy": "2025-03-26T11:52:33.730354Z",
     "iopub.status.idle": "2025-03-26T11:52:33.735643Z",
     "shell.execute_reply": "2025-03-26T11:52:33.734995Z"
    },
    "papermill": {
     "duration": 0.01132,
     "end_time": "2025-03-26T11:52:33.736723",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.725403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class BiGRUAudioClassifier(nn.Module):\n",
    "    def __init__(self,input_size, num_classes, hidden_units, num_layers):\n",
    "        super(BiGRUAudioClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.bigru = nn.GRU(input_size=input_size, hidden_size=hidden_units, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        # self.fc = nn.Linear(hidden_units, num_classes)\n",
    "        self.fc = nn.Linear(hidden_units * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, sequence_length, num_features)\n",
    "\n",
    "        # Pass the input through the bi-GRU layers\n",
    "        output, _ = self.bigru(x)\n",
    "        output = self.dropout(output)\n",
    "        # Extract the last hidden state (concatenate forward and backward hidden states)\n",
    "        last_hidden_state = torch.cat((output[:, -1, :self.hidden_units], output[:, 0, self.hidden_units:]), dim=1)\n",
    "        # Apply the fully connected layer for classification\n",
    "        output = self.fc(last_hidden_state)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abed46bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.746324Z",
     "iopub.status.busy": "2025-03-26T11:52:33.746097Z",
     "iopub.status.idle": "2025-03-26T11:52:33.774660Z",
     "shell.execute_reply": "2025-03-26T11:52:33.773594Z"
    },
    "papermill": {
     "duration": 0.03501,
     "end_time": "2025-03-26T11:52:33.776095",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.741085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiGRUAudioClassifier(\n",
      "  (bigru): GRU(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 20\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "model = BiGRUAudioClassifier(input_size, num_classes, hidden_size, num_layers)\n",
    "model.to(device, dtype=torch.double)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d42858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T11:52:33.786539Z",
     "iopub.status.busy": "2025-03-26T11:52:33.786279Z",
     "iopub.status.idle": "2025-03-26T17:53:14.498623Z",
     "shell.execute_reply": "2025-03-26T17:53:14.497751Z"
    },
    "papermill": {
     "duration": 21640.719251,
     "end_time": "2025-03-26T17:53:14.500075",
     "exception": false,
     "start_time": "2025-03-26T11:52:33.780824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [48:34<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [06:04<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10   Train Loss: 0.3830   Train Accuracy: 0.8305   Validation Accuracy: 0.9283\n",
      "\n",
      "Epoch 2/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [28:49<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [02:54<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10   Train Loss: 0.2283   Train Accuracy: 0.9160   Validation Accuracy: 0.9375\n",
      "\n",
      "Epoch 3/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [29:27<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:08<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10   Train Loss: 0.2150   Train Accuracy: 0.9211   Validation Accuracy: 0.9392\n",
      "\n",
      "Epoch 4/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [28:39<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:01<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10   Train Loss: 0.2004   Train Accuracy: 0.9273   Validation Accuracy: 0.8772\n",
      "\n",
      "Epoch 5/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:21<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:46<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10   Train Loss: 0.2057   Train Accuracy: 0.9258   Validation Accuracy: 0.9366\n",
      "\n",
      "Epoch 6/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:36<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10   Train Loss: 0.2172   Train Accuracy: 0.9205   Validation Accuracy: 0.8873\n",
      "\n",
      "Epoch 7/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:09<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:38<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10   Train Loss: 0.2222   Train Accuracy: 0.9177   Validation Accuracy: 0.9328\n",
      "\n",
      "Epoch 8/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:14<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:39<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10   Train Loss: 0.2043   Train Accuracy: 0.9255   Validation Accuracy: 0.9429\n",
      "\n",
      "Epoch 9/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:17<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:44<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10   Train Loss: 0.2081   Train Accuracy: 0.9243   Validation Accuracy: 0.9293\n",
      "\n",
      "Epoch 10/10 - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6125/6125 [31:28<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [03:40<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10   Train Loss: 0.2002   Train Accuracy: 0.9264   Validation Accuracy: 0.9154\n",
      "\n",
      "Training Complete!\n",
      "Best Validation Accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Track performance\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "max_acc = 0\n",
    "\n",
    "# Labels for best model tracking\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # =================== üî• Training Phase üî• =================== #\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Training...\")\n",
    "    \n",
    "    for images, labels in tqdm(train_dataloader, desc=\"Training Batches\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass & optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute loss & accuracy\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        train_accuracy += (predictions == labels).sum().item()\n",
    "\n",
    "    # Average loss & accuracy\n",
    "    train_loss /= train_count\n",
    "    train_accuracy /= train_count\n",
    "    \n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    # =================== üìä Validation Phase üìä =================== #\n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    pred, lab = [], []\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Validating...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_dataloader, desc=\"Validation Batches\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            val_accuracy += (predictions == labels).sum().item()\n",
    "\n",
    "            pred.extend(predictions.cpu().tolist())\n",
    "            lab.extend(labels.cpu().tolist())\n",
    "\n",
    "    # Compute validation accuracy\n",
    "    val_accuracy /= val_count\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "    # Save the best model based on validation accuracy\n",
    "    if val_accuracy > max_acc:\n",
    "        max_acc = val_accuracy\n",
    "        pred_labels = pred\n",
    "        actual_labels = lab\n",
    "        torch.save(model, \"best_accuracy_model_BiLSTM.pth\")\n",
    "\n",
    "    # Print results for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}   \"\n",
    "          f\"Train Loss: {train_loss:.4f}   \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}   \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# =================== üèÜ Final Results üèÜ =================== #\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Best Validation Accuracy: {max_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c59279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:53:21.970702Z",
     "iopub.status.busy": "2025-03-26T17:53:21.970384Z",
     "iopub.status.idle": "2025-03-26T17:53:21.974068Z",
     "shell.execute_reply": "2025-03-26T17:53:21.973235Z"
    },
    "papermill": {
     "duration": 3.737275,
     "end_time": "2025-03-26T17:53:21.975508",
     "exception": false,
     "start_time": "2025-03-26T17:53:18.238233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# best_model = torch.load(\"best_accuracy_model_BiLSTM.pth\")\n",
    "\n",
    "# # Put the best_model in evaluation mode\n",
    "# best_model.eval()\n",
    "\n",
    "# # Initialize variables to store results\n",
    "# testing_accuracy = 0.0\n",
    "# pred_labels = []\n",
    "# act_labels = []\n",
    "\n",
    "# # Pass validation data through the best model\n",
    "# for i, (images, labels) in enumerate(test_dataloader):\n",
    "#     if torch.cuda.is_available():\n",
    "#         images = Variable(images.cuda())\n",
    "#         labels = Variable(labels.cuda())\n",
    "    \n",
    "#     outputs = best_model(images)\n",
    "#     _, prediction = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     testing_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "#     pred_labels.extend(prediction.tolist())\n",
    "#     act_labels.extend(labels.tolist())\n",
    "\n",
    "# # Calculate validation accuracy\n",
    "# testing_accuracy = testing_accuracy / len(test_dataloader.dataset)\n",
    "\n",
    "# # Print the validation accuracy\n",
    "# print(\"testing Accuracy:\", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b92ab121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:53:29.212390Z",
     "iopub.status.busy": "2025-03-26T17:53:29.212053Z",
     "iopub.status.idle": "2025-03-26T17:53:29.215557Z",
     "shell.execute_reply": "2025-03-26T17:53:29.214704Z"
    },
    "papermill": {
     "duration": 3.637253,
     "end_time": "2025-03-26T17:53:29.216889",
     "exception": false,
     "start_time": "2025-03-26T17:53:25.579636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Calculate the confusion matrix\n",
    "# import seaborn as sns\n",
    "# conf_mat = confusion_matrix(act_labels, pred_labels)\n",
    "# # Plot confusion matrix heat map\n",
    "# sns.heatmap(conf_mat, cmap=\"flare\",annot=True, fmt = \"g\", \n",
    "#             cbar_kws={\"label\":\"color bar\"},\n",
    "#             xticklabels=train_dataset.classes,\n",
    "#             yticklabels=train_dataset.classes)\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Actual\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.savefig(\"ConfusionMatrix_BiLSTM.png\")\n",
    "# plt.show()\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1_score = f1_score(pred_labels, act_labels, average='macro')\n",
    "# print('F1 Score : ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265aeaa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:53:36.479673Z",
     "iopub.status.busy": "2025-03-26T17:53:36.479381Z",
     "iopub.status.idle": "2025-03-26T17:53:36.482811Z",
     "shell.execute_reply": "2025-03-26T17:53:36.482143Z"
    },
    "papermill": {
     "duration": 3.703241,
     "end_time": "2025-03-26T17:53:36.484002",
     "exception": false,
     "start_time": "2025-03-26T17:53:32.780761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import sklearn.metrics\n",
    "\n",
    "# \"\"\"\n",
    "# Python compute equal error rate (eer)\n",
    "# ONLY tested on binary classification\n",
    "\n",
    "# :param label: ground-truth label, should be a 1-d list or np.array, each element represents the ground-truth label of one sample\n",
    "# :param pred: model prediction, should be a 1-d list or np.array, each element represents the model prediction of one sample\n",
    "# :param positive_label: the class that is viewed as positive class when computing EER\n",
    "# :return: equal error rate (EER)\n",
    "# \"\"\"\n",
    "# def compute_eer(label, pred):\n",
    "#     # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "#     fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred)\n",
    "#     fnr = 1 - tpr\n",
    "\n",
    "#     # the threshold of fnr == fpr\n",
    "#     eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "#     # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "#     eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "#     eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "#     # return the mean of eer from fpr and from fnr\n",
    "#     eer = (eer_1 + eer_2) / 2\n",
    "#     return eer\n",
    "\n",
    "# eer = compute_eer(act_labels, pred_labels)\n",
    "# print('The equal error rate is {:.3f}'.format(eer))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6960546,
     "sourceId": 11156044,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6961676,
     "sourceId": 11157532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21702.355887,
   "end_time": "2025-03-26T17:53:43.051176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T11:52:00.695289",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
