{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n",
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Source folders (replace with your actual paths)\n",
    "real_src = r\"D:\\Devanshi_Himanshi_SingFox\\_6_Tracks\\T5\\real\"\n",
    "fake_src = r\"D:\\Devanshi_Himanshi_SingFox\\_6_Tracks\\T5\\fake\"\n",
    "target_root = r\"D:\\Devanshi_Himanshi_SingFox\\SingFox_ICASSP\\T5\"\n",
    "\n",
    "# Config\n",
    "split_ratio = [0.7, 0.15, 0.15]\n",
    "supported_ext = ('.mp3', '.wav', '.flac', '.WAV', '.m4a', '.aac', '.ogg')\n",
    "target_sr = 16000\n",
    "\n",
    "# Create dataset structure\n",
    "splits = ['train', 'val', 'test']\n",
    "labels = ['real', 'fake']\n",
    "for split in splits:\n",
    "    for label in labels:\n",
    "        os.makedirs(os.path.join(target_root, split, label), exist_ok=True)\n",
    "\n",
    "def collect_files(src_root, label):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(src_root):\n",
    "        for fname in filenames:\n",
    "            if fname.lower().endswith(supported_ext):\n",
    "                # Extract language as last-but-one folder\n",
    "                parts = Path(root).parts\n",
    "                lang = parts[-1] if len(parts) >= 2 else \"unknown\"\n",
    "                full_path = os.path.join(root, fname)\n",
    "                files.append({\n",
    "                    'original_path': full_path,\n",
    "                    'original_filename': fname,\n",
    "                    'language': lang,\n",
    "                    'label': label\n",
    "                })\n",
    "    return files\n",
    "\n",
    "def convert_to_wav_librosa(src_path, dest_path):\n",
    "    y, _ = librosa.load(src_path, sr=target_sr, mono=True)\n",
    "    sf.write(dest_path, y, target_sr)\n",
    "\n",
    "def process_and_split(file_list, label):\n",
    "    random.shuffle(file_list)\n",
    "    total = len(file_list)\n",
    "    n_train = int(total * split_ratio[0])\n",
    "    n_val = int(total * split_ratio[1])\n",
    "    n_test = total - n_train - n_val\n",
    "    splits_list = ['train'] * n_train + ['val'] * n_val + ['test'] * n_test\n",
    "\n",
    "    dataset_info = []\n",
    "    missing_files = []\n",
    "\n",
    "    print(f\"üîÑ Processing {label.upper()} files...\")\n",
    "    for file_info, split in tqdm(zip(file_list, splits_list), total=len(splits_list), desc=f\"{label.upper()}\"):\n",
    "        src_file = file_info['original_path']\n",
    "\n",
    "        # Check if file actually exists\n",
    "        if not os.path.exists(src_file):\n",
    "            print(f\"‚ö†Ô∏è Missing file: {src_file}\")\n",
    "            missing_files.append(src_file)\n",
    "            continue\n",
    "\n",
    "        base_name = Path(src_file).stem\n",
    "        dest_dir = os.path.join(target_root, split, label)\n",
    "        dest_path = os.path.join(dest_dir, f\"{base_name}.wav\")\n",
    "\n",
    "        # Avoid overwriting\n",
    "        i = 1\n",
    "        while os.path.exists(dest_path):\n",
    "            dest_path = os.path.join(dest_dir, f\"{base_name}_{i}.wav\")\n",
    "            i += 1\n",
    "\n",
    "        try:\n",
    "            convert_to_wav_librosa(src_file, dest_path)\n",
    "            rel_path = os.path.relpath(dest_path, target_root)\n",
    "\n",
    "            dataset_info.append({\n",
    "                'original_filename': Path(src_file).name,\n",
    "                'language': file_info['language'],\n",
    "                'original_path': src_file,\n",
    "                'label': label,\n",
    "                'split': split,\n",
    "                'saved_path': rel_path\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to convert {src_file}: {e}\")\n",
    "            missing_files.append(src_file)\n",
    "\n",
    "    if missing_files:\n",
    "        miss_log_path = os.path.join(target_root, f'missing_files_{label}.txt')\n",
    "        with open(miss_log_path, 'w', encoding='utf-8') as f:\n",
    "            for path in missing_files:\n",
    "                f.write(f\"{path}\\n\")\n",
    "        print(f\"üìù Missing file list saved to: {miss_log_path}\")\n",
    "\n",
    "    return dataset_info\n",
    "\n",
    "# Main execution\n",
    "real_files = collect_files(real_src, 'real')\n",
    "fake_files = collect_files(fake_src, 'fake')\n",
    "\n",
    "info_real = process_and_split(real_files, 'real')\n",
    "info_fake = process_and_split(fake_files, 'fake')\n",
    "\n",
    "# Save Excel\n",
    "df = pd.DataFrame(info_real + info_fake)\n",
    "df.to_excel(os.path.join(target_root, 'dataset_info.xlsx'), index=False)\n",
    "\n",
    "print(\"‚úÖ Dataset prepared and Excel saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
